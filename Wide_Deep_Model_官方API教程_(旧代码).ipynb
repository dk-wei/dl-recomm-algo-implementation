{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wide Deep Model 官方API教程 (旧代码).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FSRej--ljEF"
      },
      "source": [
        "#!sudo apt-get install python-pip python-dev"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU--Xi-k4gsW"
      },
      "source": [
        "原文以及repo:[TensorFlow Wide & Deep Learning Tutorial (TF 1.12版本)](https://github.com/baidu-research/tensorflow-allreduce/blob/master/tensorflow/docs_src/tutorials/wide_and_deep.md), 还有[chrominium版本 (TF 2.0+版本)](https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.10/tensorflow/g3doc/tutorials/wide_and_deep/index.md)\n",
        "\n",
        "> 这篇Tutorial的目标主要是怎么使用`DNNLinearCombinedClassifier`这个High level API，我们需要学习的主要是如何处理categorical feature以及numeric feature，还有**feature crossing**.\n",
        "\n",
        "In the previous [TensorFlow Linear Model Tutorial](https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.10/tensorflow/g3doc/tutorials/wide), we trained a logistic regression model to predict the probability that the individual has an annual income of over 50,000 dollars using the [Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income). TensorFlow is great for training deep neural networks too, and you might be thinking which one you should choose—Well, why not both? Would it be possible to combine the strengths of both in one model?\n",
        "\n",
        "In this tutorial, we'll introduce how to use the tf.estimator API to jointly train a wide linear model and a deep feed-forward neural network. This approach combines the strengths of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g. categorical features with a large number of possible feature values). If you're interested in learning more about how Wide & Deep Learning works, please check out our [research paper](http://arxiv.org/abs/1606.07792)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIgqedlA4HDM"
      },
      "source": [
        "![](https://1.bp.blogspot.com/-Dw1mB9am1l8/V3MgtOzp3uI/AAAAAAAABGs/mP-3nZQCjWwdk6qCa5WraSpK8A7rSPj3ACLcB/s640/image04.png \"Wide'n'Deep\")\n",
        "\n",
        "The figure above shows a comparison of a wide model (logistic regression with sparse features and transformations), a deep model (feed-forward neural network with an embedding layer and several hidden layers), and a Wide & Deep model (joint training of both). At a high level, there are only 3 steps to configure a wide, deep, or Wide & Deep model using the TF.Learn API:\n",
        "\n",
        "1. Select features for the **WIDE** part: Choose the `sparse base columns` and `crossed columns` you want to use.\n",
        "2. Select features for the **DEEP** part: Choose the `continuous columns`, the `embedding dimension for each categorical column`, and the hidden layer sizes.\n",
        "3. Put them all together in a Wide & Deep model (`DNNLinearCombinedClassifier`).\n",
        "\n",
        "And that‘s it! Let’s go through a simple example.\n",
        "\n",
        "原代码链接已失效，新链接见此处:[wide_n_deep_tutorial.py](https://github.com/baidu-research/tensorflow-allreduce/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVEkvgGIljA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb08cee-c1e8-4421-8afd-3ae305281062"
      },
      "source": [
        "!python wide_n_deep_tutorial.py --model_type=wide_n_deep"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'wide_n_deep_tutorial.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hYxHgDS553m"
      },
      "source": [
        "注意，这篇tutorial有几个坑：\n",
        "1. python为2.7环境  \n",
        "2. TensorFlow为1.12.0版本\n",
        "\n",
        "所以一上来就要给TF降级："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PctjDXMjphg4"
      },
      "source": [
        "#!pip install tensorflow==1.14.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-27hfPZwmT49",
        "outputId": "2f11fb52-fed7-42fe-c69e-4b3bc0c20c59"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj-bOmhZBEUO"
      },
      "source": [
        "# A Glance of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DobtpAFYA6rc"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "import tempfile\n",
        "\n",
        "# Define the column names for the data sets.\n",
        "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
        "  \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
        "  \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
        "LABEL_COLUMN = 'label'\n",
        "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
        "                       \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
        "CONTINUOUS_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\",\n",
        "                      \"hours_per_week\"]\n",
        "\n",
        "# Download the training and test data to temporary files.\n",
        "# Alternatively, you can download them yourself and change train_file and\n",
        "# test_file to your own paths.\n",
        "train_file = tempfile.NamedTemporaryFile()\n",
        "test_file = tempfile.NamedTemporaryFile()\n",
        "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", train_file.name)\n",
        "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", test_file.name)\n",
        "\n",
        "# Read the training and test data sets into Pandas dataframe.\n",
        "df_train = pd.read_csv(train_file, names=COLUMNS, skipinitialspace=True)\n",
        "df_test = pd.read_csv(test_file, names=COLUMNS, skipinitialspace=True, skiprows=1)\n",
        "df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)\n",
        "df_test[LABEL_COLUMN] = (df_test['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "RCKwIudDBLao",
        "outputId": "cfcc9052-08be-4824-dff4-c97ddb56f1e8"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass  fnlwgt  ... native_country  income_bracket label\n",
              "0   39         State-gov   77516  ...  United-States           <=50K     0\n",
              "1   50  Self-emp-not-inc   83311  ...  United-States           <=50K     0\n",
              "2   38           Private  215646  ...  United-States           <=50K     0\n",
              "3   53           Private  234721  ...  United-States           <=50K     0\n",
              "4   28           Private  338409  ...           Cuba           <=50K     0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anOSpHStnvDv",
        "outputId": "f5513ce4-8db5-4d78-b1f0-38dd69735433"
      },
      "source": [
        "df_train.education.unique()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
              "       'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
              "       '5th-6th', '10th', '1st-4th', 'Preschool', '12th'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw4YU9W978TY"
      },
      "source": [
        "# Define Base Feature Columns\n",
        "\n",
        "First, let's define the base `categorical` and `continuous` feature columns that we'll use. **These base columns will be the building blocks used by both the wide part and the deep part of the model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGmaXRgOli_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7f1405-979b-45c9-882c-20d96d317a58"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#  Continuous base columns.\n",
        "## bucketized cols\n",
        "age = tf.contrib.layers.real_valued_column(\"age\")\n",
        "education_num = tf.contrib.layers.real_valued_column(\"education_num\")\n",
        "capital_gain = tf.contrib.layers.real_valued_column(\"capital_gain\")\n",
        "capital_loss = tf.contrib.layers.real_valued_column(\"capital_loss\")\n",
        "hours_per_week = tf.contrib.layers.real_valued_column(\"hours_per_week\")\n",
        "\n",
        "\n",
        "#  Categorical base columns.\n",
        "## 类别较少的categorcial feature: sparse_column_with_keys()\n",
        "gender = tf.contrib.layers.sparse_column_with_keys(column_name=\"gender\", keys=[\"female\", \"male\"])\n",
        "race = tf.contrib.layers.sparse_column_with_keys(column_name=\"race\", keys=[\"Amer-Indian-Eskimo\", \n",
        "                                                                           \"Asian-Pac-Islander\", \n",
        "                                                                           \"Black\", \n",
        "                                                                           \"Other\", \n",
        "                                                                           \"White\"]\n",
        "                                                 )\n",
        "## 类别较多的categorcial feature: sparse_column_with_hash_bucket()\n",
        "education = tf.contrib.layers.sparse_column_with_hash_bucket(\"education\", hash_bucket_size=1000)\n",
        "marital_status = tf.contrib.layers.sparse_column_with_hash_bucket(\"marital_status\", hash_bucket_size=100)\n",
        "relationship = tf.contrib.layers.sparse_column_with_hash_bucket(\"relationship\", hash_bucket_size=100)\n",
        "workclass = tf.contrib.layers.sparse_column_with_hash_bucket(\"workclass\", hash_bucket_size=100)\n",
        "occupation = tf.contrib.layers.sparse_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
        "native_country = tf.contrib.layers.sparse_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)\n",
        "\n",
        "# Transformations.\n",
        "age_buckets = tf.contrib.layers.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ7RFpowvqBK"
      },
      "source": [
        "# # To show an example of hashing:\n",
        "# occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "#     \"occupation\", hash_bucket_size=1000)\n",
        "# native_country = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "#     \"native_country\", hash_bucket_size=1000)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqVphnf38iuT"
      },
      "source": [
        "# The Wide Model: Linear Model with Crossed Feature Columns\n",
        "The wide model is a linear model with a wide set of sparse and crossed feature columns:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCvbUgO9li8W"
      },
      "source": [
        "wide_columns = [\n",
        "  gender, native_country, education, occupation, workclass, marital_status, relationship, age_buckets,\n",
        "  tf.contrib.layers.crossed_column([education, occupation], hash_bucket_size=int(1e4)),               # 将education和occupation两者做feature crossing\n",
        "  tf.contrib.layers.crossed_column([native_country, occupation], hash_bucket_size=int(1e4)),\n",
        "  tf.contrib.layers.crossed_column([age_buckets, race, occupation], hash_bucket_size=int(1e6))]      # 将age_buckets， race和occupation三者做feature crossing"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdKonUlgquK2",
        "outputId": "9fc78635-9f3c-4fba-d3a0-9e60c6af4481"
      },
      "source": [
        "wide_columns # 可以看到全是各种feature column"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[_SparseColumnKeys(column_name='gender', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('female', 'male'), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
              " _SparseColumnHashed(column_name='native_country', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string),\n",
              " _SparseColumnHashed(column_name='education', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string),\n",
              " _SparseColumnHashed(column_name='occupation', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string),\n",
              " _SparseColumnHashed(column_name='workclass', is_integerized=False, bucket_size=100, lookup_config=None, combiner='sum', dtype=tf.string),\n",
              " _SparseColumnHashed(column_name='marital_status', is_integerized=False, bucket_size=100, lookup_config=None, combiner='sum', dtype=tf.string),\n",
              " _SparseColumnHashed(column_name='relationship', is_integerized=False, bucket_size=100, lookup_config=None, combiner='sum', dtype=tf.string),\n",
              " _BucketizedColumn(source_column=_RealValuedColumn(column_name='age', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)),\n",
              " _CrossedColumn(columns=(_SparseColumnHashed(column_name='education', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='occupation', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string)), hash_bucket_size=10000, hash_key=None, combiner='sum', ckpt_to_load_from=None, tensor_name_in_ckpt=None),\n",
              " _CrossedColumn(columns=(_SparseColumnHashed(column_name='native_country', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='occupation', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string)), hash_bucket_size=10000, hash_key=None, combiner='sum', ckpt_to_load_from=None, tensor_name_in_ckpt=None),\n",
              " _CrossedColumn(columns=(_BucketizedColumn(source_column=_RealValuedColumn(column_name='age', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _SparseColumnHashed(column_name='occupation', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnKeys(column_name='race', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'), num_oov_buckets=0, vocab_size=5, default_value=-1), combiner='sum', dtype=tf.string)), hash_bucket_size=1000000, hash_key=None, combiner='sum', ckpt_to_load_from=None, tensor_name_in_ckpt=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtINln978p1g"
      },
      "source": [
        "Wide models with crossed feature columns can memorize sparse interactions between features effectively. That being said, one limitation of crossed feature columns is that they do not generalize to feature combinations that have not appeared in the training data. Let's add a deep model with embeddings to fix that.\n",
        "\n",
        "# The Deep Model: Neural Network with Embeddings\n",
        "The deep model is a feed-forward neural network, as shown in the previous figure. **Each of the sparse, high-dimensional `categorical features` are first converted into a low-dimensional and dense real-valued vector, often referred to as an embedding vector**. These low-dimensional dense embedding vectors are concatenated with the continuous features, and then fed into the hidden layers of a neural network in the forward pass. The embedding values are initialized randomly, and are trained along with all other model parameters to minimize the training loss. If you're interested in learning more about embeddings, check out the TensorFlow tutorial on [Vector Representations of Words](https://www.tensorflow.org/versions/r0.9/tutorials/word2vec/index.html), or Word Embedding on Wikipedia.\n",
        "\n",
        "Another way to represent categorical columns to feed into a neural network is via a multi-hot representation. This is often appropriate for categorical columns with only a few possible values. E.g. for the gender column, \"Male\" can be represented as [1, 0] and \"Female\" as [0, 1]. This is a fixed representation, whereas embeddings are more flexible and calculated at training time.\n",
        "\n",
        "We'll configure the embeddings for the categorical columns using embedding_column, and concatenate them with the continuous columns. We also use indicator_column to create multi-hot representation of some categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNfyq4pqli5v",
        "outputId": "cc038947-aea3-488d-9b1e-e327a30b3769"
      },
      "source": [
        "# 对categorical feature的政策就是全部要embedding\n",
        "deep_columns = [\n",
        "  tf.contrib.layers.embedding_column(workclass, dimension=8),   # dimension越大准确性越高\n",
        "  tf.contrib.layers.embedding_column(education, dimension=8),\n",
        "  tf.contrib.layers.embedding_column(marital_status, dimension=8),\n",
        "  tf.contrib.layers.embedding_column(gender, dimension=8),\n",
        "  tf.contrib.layers.embedding_column(relationship, dimension=8),\n",
        "  tf.contrib.layers.embedding_column(race, dimension=8),\n",
        "  tf.contrib.layers.embedding_column(native_country, dimension=8),\n",
        "  tf.contrib.layers.embedding_column(occupation, dimension=8),\n",
        "  age, education_num, capital_gain, capital_loss, hours_per_week\n",
        "  ]\n",
        "\n",
        "\n",
        "# TF 2.0+版本差异还挺大\n",
        "#  deep_columns = [\n",
        "#     tf.feature_column.indicator_column(workclass),\n",
        "#     tf.feature_column.indicator_column(education),\n",
        "#     tf.feature_column.indicator_column(gender),\n",
        "#     tf.feature_column.indicator_column(relationship),\n",
        "#     # To show an example of embedding\n",
        "#     tf.feature_column.embedding_column(native_country, dimension=8),\n",
        "#     tf.feature_column.embedding_column(occupation, dimension=8),\n",
        "#     age,\n",
        "#     education_num,\n",
        "#     capital_gain,\n",
        "#     capital_loss,\n",
        "#     hours_per_week,\n",
        "# ] "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
            "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
            "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
            "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
            "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
            "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
            "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
            "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwlhHlv587yE"
      },
      "source": [
        "The higher the dimension of the embedding is, the more degrees of freedom the model will have to learn the representations of the features. For simplicity, we set the dimension to 8 for all feature columns here. **Empirically, a more informed decision for the number of dimensions is to start with a value on the order of $(\\log_2(n))$ or $(k\\sqrt[4]n)$, where $(n)$ is the number of unique features in a feature column and $(k)$ is a small constant (usually smaller than 10)**. \n",
        "\n",
        "Through dense embeddings, deep models can generalize better and make predictions on feature pairs that were previously unseen in the training data. (**Deep model优点是通过dense embedding, 很多没有pair过的feature现在也能找到相关性了**) However, it is difficult to learn effective low-dimensional representations for feature columns when the underlying interaction matrix between two feature columns is sparse and high-rank. In such cases, the interaction between most feature pairs should be zero except a few, but dense embeddings will lead to nonzero predictions for all feature pairs, and thus can over-generalize. (**Deep model缺点是学到的很多相关性太泛泛**)On the other hand, linear models with crossed features can memorize these “exception rules” effectively with fewer model parameters.\n",
        "\n",
        "Now, let's see how to jointly train wide and deep models and allow them to complement each other’s strengths and weaknesses.\n",
        "\n",
        "## Feature 汇总\n",
        "- Wide part：\n",
        " - gender \n",
        " - native_country\n",
        " - education\n",
        " - occupation\n",
        " - workclass\n",
        " - marital_status\n",
        " - relationship \n",
        " - age_buckets,\n",
        " - education X occupation \n",
        " - native_country X occupation\n",
        " - age_buckets X race X occupation\n",
        "- Deep part:\n",
        " - workclass \n",
        " - education\n",
        " - marital_status\n",
        " - gender\n",
        " - relationship\n",
        " - race\n",
        " - native_country\n",
        " - occupation\n",
        " - age\n",
        " - education_num \n",
        " - capital_gain \n",
        " - capital_loss,\n",
        " - hours_per_week\n",
        "\n",
        "\n",
        "#Combining Wide and Deep Models into One\n",
        "**The wide models and deep models are combined by summing up their final output log odds as the prediction, then feeding the prediction to a logistic loss function**. All the graph definition and variable allocations have already been handled for you under the hood, so you simply need to create a `DNNLinearCombinedClassifier`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcVyWTgqli3K",
        "outputId": "675e8e4c-df78-4658-cfb0-0a8ef1437e78"
      },
      "source": [
        "import tempfile\n",
        "model_dir = tempfile.mkdtemp()\n",
        "\n",
        "# 只需要提供wide和deep column的数据，剩下的DNNLinearCombinedClassifier()来处理\n",
        "m = tf.contrib.learn.DNNLinearCombinedClassifier(\n",
        "    model_dir=model_dir,\n",
        "    linear_feature_columns=wide_columns,\n",
        "    dnn_feature_columns=deep_columns,\n",
        "    dnn_hidden_units=[100, 50])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-2702c9bb1bef>:9: calling DNNLinearCombinedClassifier.__init__ (from tensorflow.contrib.learn.python.learn.estimators.dnn_linear_combined) with fix_global_step_increment_bug=False is deprecated and will be removed after 2017-04-15.\n",
            "Instructions for updating:\n",
            "Please set fix_global_step_increment_bug=True and update training steps in your pipeline. See pydoc for details.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py:676: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f048e43b400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmp3ba6ehd3'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHCvilh19dp4"
      },
      "source": [
        "#Training and Evaluating The Model\n",
        "Before we train the model, let's read in the Census dataset as we did in the[TensorFlow Linear Model tutorial](https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.10/tensorflow/g3doc/tutorials/wide). The code for input data processing is provided here again for your convenience:\n",
        "\n",
        "注：这个模型厉害的地方在于，可能线下训练的Top 1的AUC看起来一般般，但是上线之后推荐多个结果的TopN整体效果很好，会包含很多新的有意思的app。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Et9agUli0s"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "# Define the column names for the data sets.\n",
        "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
        "  \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
        "  \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
        "LABEL_COLUMN = 'label'\n",
        "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
        "                       \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
        "CONTINUOUS_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\",\n",
        "                      \"hours_per_week\"]\n",
        "\n",
        "# Download the training and test data to temporary files.\n",
        "# Alternatively, you can download them yourself and change train_file and\n",
        "# test_file to your own paths.\n",
        "train_file = tempfile.NamedTemporaryFile()\n",
        "test_file = tempfile.NamedTemporaryFile()\n",
        "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", train_file.name)\n",
        "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", test_file.name)\n",
        "\n",
        "# Read the training and test data sets into Pandas dataframe.\n",
        "df_train = pd.read_csv(train_file, names=COLUMNS, skipinitialspace=True)\n",
        "df_test = pd.read_csv(test_file, names=COLUMNS, skipinitialspace=True, skiprows=1)\n",
        "df_train[LABEL_COLUMN] = (df_train['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)\n",
        "df_test[LABEL_COLUMN] = (df_test['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "84_IDF6jtJEW",
        "outputId": "fc101f24-84a7-433a-a931-ed035433fb02"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass  fnlwgt  ... native_country  income_bracket label\n",
              "0   39         State-gov   77516  ...  United-States           <=50K     0\n",
              "1   50  Self-emp-not-inc   83311  ...  United-States           <=50K     0\n",
              "2   38           Private  215646  ...  United-States           <=50K     0\n",
              "3   53           Private  234721  ...  United-States           <=50K     0\n",
              "4   28           Private  338409  ...           Cuba           <=50K     0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRtTrMwVt6sO"
      },
      "source": [
        "def input_fn(df):\n",
        "  # Creates a dictionary mapping from each continuous feature column name (k) to\n",
        "  # the values of that column stored in a constant Tensor.\n",
        "  continuous_cols = {k: tf.constant(df[k].values)\n",
        "                     for k in CONTINUOUS_COLUMNS}\n",
        "\n",
        "  # Creates a dictionary mapping from each categorical feature column name (k)\n",
        "  # to the values of that column stored in a tf.SparseTensor.\n",
        "  categorical_cols = {k: tf.SparseTensor(\n",
        "      indices=[[i, 0] for i in range(df[k].size)],\n",
        "      values=df[k].values,\n",
        "      dense_shape=[df[k].size, 1]) for k in CATEGORICAL_COLUMNS\n",
        "      }\n",
        "\n",
        "  # Merges the two dictionaries into one.\n",
        "  feature_cols = dict(continuous_cols.items() | categorical_cols.items())\n",
        "  \n",
        "  # Converts the label column into a constant Tensor.\n",
        "  label = tf.constant(df[LABEL_COLUMN].values)\n",
        "\n",
        "  # Returns the feature columns and the label.\n",
        "  print(continuous_cols, feature_cols, label)\n",
        "  \n",
        "  return feature_cols, label\n",
        "\n",
        "def train_input_fn():\n",
        "  return input_fn(df_train)\n",
        "\n",
        "def eval_input_fn():\n",
        "  return input_fn(df_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouub3Plnw1kY",
        "outputId": "7670bc5b-b872-4c7e-e44e-1e42d7f4be3f"
      },
      "source": [
        "input_fn(df_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'age': <tf.Tensor 'Const:0' shape=(32561,) dtype=int64>, 'education_num': <tf.Tensor 'Const_1:0' shape=(32561,) dtype=int64>, 'capital_gain': <tf.Tensor 'Const_2:0' shape=(32561,) dtype=int64>, 'capital_loss': <tf.Tensor 'Const_3:0' shape=(32561,) dtype=int64>, 'hours_per_week': <tf.Tensor 'Const_4:0' shape=(32561,) dtype=int64>} {'native_country': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f048e476f28>, 'age': <tf.Tensor 'Const:0' shape=(32561,) dtype=int64>, 'capital_gain': <tf.Tensor 'Const_2:0' shape=(32561,) dtype=int64>, 'gender': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f04833c0da0>, 'hours_per_week': <tf.Tensor 'Const_4:0' shape=(32561,) dtype=int64>, 'marital_status': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f04aa0e9198>, 'relationship': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f048e43b3c8>, 'education_num': <tf.Tensor 'Const_1:0' shape=(32561,) dtype=int64>, 'capital_loss': <tf.Tensor 'Const_3:0' shape=(32561,) dtype=int64>, 'workclass': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0482d84f28>, 'occupation': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f048341d0b8>, 'education': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f048389cc88>, 'race': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0482d81c18>} Tensor(\"Const_5:0\", shape=(32561,), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'age': <tf.Tensor 'Const:0' shape=(32561,) dtype=int64>,\n",
              "  'capital_gain': <tf.Tensor 'Const_2:0' shape=(32561,) dtype=int64>,\n",
              "  'capital_loss': <tf.Tensor 'Const_3:0' shape=(32561,) dtype=int64>,\n",
              "  'education': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f048389cc88>,\n",
              "  'education_num': <tf.Tensor 'Const_1:0' shape=(32561,) dtype=int64>,\n",
              "  'gender': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f04833c0da0>,\n",
              "  'hours_per_week': <tf.Tensor 'Const_4:0' shape=(32561,) dtype=int64>,\n",
              "  'marital_status': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f04aa0e9198>,\n",
              "  'native_country': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f048e476f28>,\n",
              "  'occupation': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f048341d0b8>,\n",
              "  'race': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f0482d81c18>,\n",
              "  'relationship': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f048e43b3c8>,\n",
              "  'workclass': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f0482d84f28>},\n",
              " <tf.Tensor 'Const_5:0' shape=(32561,) dtype=int64>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwGFgXGf-L6F"
      },
      "source": [
        "After reading in the data, you can train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwGSs80olixR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05c585e-048e-4051-d88b-fdc148ca6391"
      },
      "source": [
        "m.fit(input_fn=train_input_fn, steps=200)\n",
        "\n",
        "results = m.evaluate(input_fn=eval_input_fn, steps=1)\n",
        "# for key in sorted(results):\n",
        "#     print (\"%s: %s\" % (key, results[key]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'age': <tf.Tensor 'Const:0' shape=(32561,) dtype=int64>, 'education_num': <tf.Tensor 'Const_1:0' shape=(32561,) dtype=int64>, 'capital_gain': <tf.Tensor 'Const_2:0' shape=(32561,) dtype=int64>, 'capital_loss': <tf.Tensor 'Const_3:0' shape=(32561,) dtype=int64>, 'hours_per_week': <tf.Tensor 'Const_4:0' shape=(32561,) dtype=int64>} {'race': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0482412668>, 'education_num': <tf.Tensor 'Const_1:0' shape=(32561,) dtype=int64>, 'gender': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0482412b70>, 'native_country': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f04824121d0>, 'hours_per_week': <tf.Tensor 'Const_4:0' shape=(32561,) dtype=int64>, 'marital_status': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f04aa0e88d0>, 'capital_loss': <tf.Tensor 'Const_3:0' shape=(32561,) dtype=int64>, 'age': <tf.Tensor 'Const:0' shape=(32561,) dtype=int64>, 'capital_gain': <tf.Tensor 'Const_2:0' shape=(32561,) dtype=int64>, 'workclass': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0482d400b8>, 'relationship': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0482d81940>, 'education': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0482d30b70>, 'occupation': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0482081c18>} Tensor(\"Const_5:0\", shape=(32561,), dtype=int64)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0482116160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0482116160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0482116160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0482116160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0482361c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0482361c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0482361c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0482361c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0481d4eb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0481d4eb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0481d4eb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0481d4eb70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2406: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
            "Instructions for updating:\n",
            "The default behavior of sparse_feature_cross is changing, the default\n",
            "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
            "From that point on sparse_feature_cross will always use FingerprintCat64\n",
            "to concatenate the feature fingerprints. And the underlying\n",
            "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
            "as deprecated.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp3ba6ehd3/model.ckpt.\n",
            "INFO:tensorflow:loss = 11.613991, step = 2\n",
            "INFO:tensorflow:global_step/sec: 7.01036\n",
            "INFO:tensorflow:loss = 1.6822622, step = 202 (25.781 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 202 into /tmp/tmp3ba6ehd3/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.6822622.\n",
            "{'age': <tf.Tensor 'Const:0' shape=(16281,) dtype=int64>, 'education_num': <tf.Tensor 'Const_1:0' shape=(16281,) dtype=int64>, 'capital_gain': <tf.Tensor 'Const_2:0' shape=(16281,) dtype=int64>, 'capital_loss': <tf.Tensor 'Const_3:0' shape=(16281,) dtype=int64>, 'hours_per_week': <tf.Tensor 'Const_4:0' shape=(16281,) dtype=int64>} {'hours_per_week': <tf.Tensor 'Const_4:0' shape=(16281,) dtype=int64>, 'education': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f047b02dc50>, 'native_country': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f047e6befd0>, 'gender': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f047e6beb00>, 'capital_gain': <tf.Tensor 'Const_2:0' shape=(16281,) dtype=int64>, 'capital_loss': <tf.Tensor 'Const_3:0' shape=(16281,) dtype=int64>, 'relationship': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f047b04a4a8>, 'age': <tf.Tensor 'Const:0' shape=(16281,) dtype=int64>, 'occupation': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f047b04a630>, 'race': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f047e6be630>, 'education_num': <tf.Tensor 'Const_1:0' shape=(16281,) dtype=int64>, 'marital_status': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f047b04ab70>, 'workclass': <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f0481b64b38>} Tensor(\"Const_5:0\", shape=(16281,), dtype=int64)\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047e7cedd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047e7cedd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047e7cedd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047e7cedd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047e7cecf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047e7cecf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047e7cecf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047e7cecf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047b059048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047b059048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047b059048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f047b059048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
            "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "INFO:tensorflow:Starting evaluation at 2021-01-25T18:01:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp3ba6ehd3/model.ckpt-202\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/1]\n",
            "INFO:tensorflow:Finished evaluation at 2021-01-25-18:01:32\n",
            "INFO:tensorflow:Saving dict for global step 202: accuracy = 0.8227382, accuracy/baseline_label_mean = 0.23622628, accuracy/threshold_0.500000_mean = 0.8227382, auc = 0.8022439, auc_precision_recall = 0.6209644, global_step = 202, labels/actual_label_mean = 0.23622628, labels/prediction_mean = 0.22765823, loss = 0.92337215, precision/positive_threshold_0.500000_mean = 0.67531043, recall/positive_threshold_0.500000_mean = 0.48075923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exoM5TfrwGYH",
        "outputId": "fcd8684b-198d-4f98-8559-fedc0cfc20aa"
      },
      "source": [
        "results"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8227382,\n",
              " 'accuracy/baseline_label_mean': 0.23622628,\n",
              " 'accuracy/threshold_0.500000_mean': 0.8227382,\n",
              " 'auc': 0.8022439,\n",
              " 'auc_precision_recall': 0.6209644,\n",
              " 'global_step': 202,\n",
              " 'labels/actual_label_mean': 0.23622628,\n",
              " 'labels/prediction_mean': 0.22765823,\n",
              " 'loss': 0.92337215,\n",
              " 'precision/positive_threshold_0.500000_mean': 0.67531043,\n",
              " 'recall/positive_threshold_0.500000_mean': 0.48075923}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytDjlxr2_4T1"
      },
      "source": [
        "The first line of the output should be something like `accuracy: 0.84429705`. We can see that the accuracy was improved from about 83.6% using a wide-only linear model to about 84.4% using a Wide & Deep model. If you'd like to see a working end-to-end example, you can download our example code.\n",
        "\n",
        "Note that this tutorial is just a quick example on a small dataset to get you familiar with the API. **Wide & Deep Learning will be even more powerful if you try it on a large dataset with many sparse feature columns that have a large number of possible feature values**. Again, feel free to take a look at our research paper for more ideas about how to apply Wide & Deep Learning in real-world large-scale machine learning problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTJLazjyliu6"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1W-_806lisC"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFF5EisMliom"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOdj55_IlfTJ"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}
