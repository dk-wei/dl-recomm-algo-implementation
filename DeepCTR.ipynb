{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepCTR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpAmsI0zutDhuYqsT7i228",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dk-wei/recommendation-algo-implementation/blob/main/DeepCTR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv7FsPdzkuO-"
      },
      "source": [
        "# DeepCTR\n",
        "\n",
        "DeepCTR is a **Easy-to-use,Modular** and **Extendible** package of deep-learning based CTR models along with lots of core components layers which can be used to easily build custom models.You can use any complex model with `model.fit()`，and `model.predict()`.\n",
        "\n",
        "- Provide tf.keras.Model like interface for **quick experiment**. example\n",
        "- Provide tensorflow estimator interface for **large scale data** and **distributed training**. example\n",
        "- It is compatible with both tf 1.x and tf 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLkfu-XyJD1v",
        "outputId": "d6994e2b-019c-44ec-fe11-a70f5c85d430"
      },
      "source": [
        "!git clone https://github.com/shenweichen/DeepCTR.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepCTR'...\n",
            "remote: Enumerating objects: 2862, done.\u001b[K\n",
            "remote: Counting objects: 100% (523/523), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 2862 (delta 365), reused 423 (delta 322), pack-reused 2339\u001b[K\n",
            "Receiving objects: 100% (2862/2862), 6.77 MiB | 18.83 MiB/s, done.\n",
            "Resolving deltas: 100% (2108/2108), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAqWaImV21Ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68909020-a685-4060-c4e6-15ce5ab1d618"
      },
      "source": [
        "!pip install deepctr[gpu]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepctr[gpu]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/2c/dd9dd105e366d80328fbbf1312d2623d41c8bfbd56ed14390b6c59d6719b/deepctr-0.8.6-py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from deepctr[gpu]) (2.23.0)\n",
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 29.8MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/a2/5ccf0a418eb22e0a2ae9edc1e7f5456d0a4b8b49524572897564b4030a9b/tensorflow_gpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr[gpu]) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr[gpu]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr[gpu]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->deepctr[gpu]) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deepctr[gpu]) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deepctr[gpu]) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.36.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.34.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.17.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (57.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (4.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (4.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: h5py, tensorflow-gpu, deepctr\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed deepctr-0.8.6 h5py-2.10.0 tensorflow-gpu-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mi6zpZUK2LP"
      },
      "source": [
        "![](https://pic3.zhimg.com/80/v2-dd98a58d2676f20ded7d7b0c61e88fa2_1440w.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G5ICFmoLNFk"
      },
      "source": [
        "DeepCTR的设计主要是面向那些对深度学习以及CTR预测算法感兴趣的同学，使他们可以利用这个包：\n",
        "\n",
        "1. 从一个统一视角来看待各个模型\n",
        "2. 快速地进行简单的对比实验\n",
        "3. 利用已有的组件快速构建新的模型\n",
        "\n",
        "# 统一视角\n",
        "\n",
        "DeepCTR通过对现有的基于深度学习的点击率预测模型的结构进行抽象总结，在设计过程中采用模块化的思路，各个模块自身具有高复用性，各个模块之间互相独立。 基于深度学习的点击率预测模型按模型内部组件的功能可以划分成以下4个模块：输入模块，嵌入模块，特征提取模块，预测输出模块。\n",
        "\n",
        "![](https://pic1.zhimg.com/80/v2-392784585d6238db7f20744e8e98c5f4_1440w.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb88GxrGMkzi"
      },
      "source": [
        "- Input & Embedding    \n",
        "The data in CTR estimation task usually includes **high sparse,high cardinality categorical features** and some dense numerical features.\n",
        "\n",
        "  Since DNN are good at handling **dense numerical features**,we usually map the **sparse categorical features** to dense numerical through embedding technique.\n",
        "\n",
        "  For **numerical features**,we usually apply **discretization** or **normalization** on them.\n",
        "\n",
        "- Feature Extractor    \n",
        "Low-order Extractor learns feature interaction through product between vectors. **Factorization-Machine (FM)** and it’s variants FFM are widely used to learn the low-order feature interaction.\n",
        "\n",
        "  High-order Extractor learns feature combination through complex neural network functions like MLP,Cross Net,etc.#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFs2RlgcQRox"
      },
      "source": [
        "## DeepFM\n",
        "\n",
        "![](http://fancyerii.github.io/img/ctr/deepfm-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE1Mr3guILTE"
      },
      "source": [
        "# Classification: Criteo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "689ojo5Gp4UV"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "4AEvSSLrq8Eh",
        "outputId": "126f84c9-ac2d-442e-b021-8f80199c5489"
      },
      "source": [
        "avazu_data = pd.read_csv('https://raw.githubusercontent.com/shenweichen/DeepCTR/master/examples/avazu_sample.txt')\n",
        "\n",
        "avazu_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>click</th>\n",
              "      <th>hour</th>\n",
              "      <th>C1</th>\n",
              "      <th>banner_pos</th>\n",
              "      <th>site_id</th>\n",
              "      <th>site_domain</th>\n",
              "      <th>site_category</th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_domain</th>\n",
              "      <th>app_category</th>\n",
              "      <th>device_id</th>\n",
              "      <th>device_ip</th>\n",
              "      <th>device_model</th>\n",
              "      <th>device_type</th>\n",
              "      <th>device_conn_type</th>\n",
              "      <th>C14</th>\n",
              "      <th>C15</th>\n",
              "      <th>C16</th>\n",
              "      <th>C17</th>\n",
              "      <th>C18</th>\n",
              "      <th>C19</th>\n",
              "      <th>C20</th>\n",
              "      <th>C21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000009418151094273</td>\n",
              "      <td>0</td>\n",
              "      <td>14102100</td>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>ddd2926e</td>\n",
              "      <td>44956a24</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>15706</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1722</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10000169349117863715</td>\n",
              "      <td>0</td>\n",
              "      <td>14102100</td>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>96809ac8</td>\n",
              "      <td>711ee120</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15704</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1722</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>100084</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10000371904215119486</td>\n",
              "      <td>0</td>\n",
              "      <td>14102100</td>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>b3cf8def</td>\n",
              "      <td>8a4875bd</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15704</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1722</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>100084</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10000640724480838376</td>\n",
              "      <td>0</td>\n",
              "      <td>14102100</td>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>e8275b8f</td>\n",
              "      <td>6332421a</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15706</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1722</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>100084</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10000679056417042096</td>\n",
              "      <td>0</td>\n",
              "      <td>14102100</td>\n",
              "      <td>1005</td>\n",
              "      <td>1</td>\n",
              "      <td>fe8cc448</td>\n",
              "      <td>9166c161</td>\n",
              "      <td>0569f928</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>9644d0bf</td>\n",
              "      <td>779d90c2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18993</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2161</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  click      hour    C1  ...  C18 C19     C20  C21\n",
              "0   1000009418151094273      0  14102100  1005  ...    0  35      -1   79\n",
              "1  10000169349117863715      0  14102100  1005  ...    0  35  100084   79\n",
              "2  10000371904215119486      0  14102100  1005  ...    0  35  100084   79\n",
              "3  10000640724480838376      0  14102100  1005  ...    0  35  100084   79\n",
              "4  10000679056417042096      0  14102100  1005  ...    0  35      -1  157\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x608-TA0rnnl"
      },
      "source": [
        "Criteo Data fields\n",
        "- Label - Target variable that indicates if an ad was clicked (1) or not (0).\n",
        "- I1-I13 - A total of 13 columns of dense numerical (integer) features (mostly *count features*).\n",
        "- C1-C26 - A total of 26 columns of sparse categorical features. The values of \n",
        "these features have been hashed onto 32 bits for anonymization purposes. \n",
        "The semantic of the features is undisclosed.\n",
        "\n",
        "When a value is missing, the field is empty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPMeN2Y02eJD"
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/shenweichen/DeepCTR/master/examples/criteo_sample.txt')\n",
        "sparse_features = ['C' + str(i) for i in range(1, 27)]    # sparse feature一般指的就是categorical feature，特别是high cardinality\n",
        "dense_features = ['I' + str(i) for i in range(1, 14)]     # dense feature一般指的就是numerical feature，还有count feature\n",
        " \n",
        "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
        "data[dense_features] = data[dense_features].fillna(0, )\n",
        "target = ['label']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "RsTzL5xN4-MO",
        "outputId": "7e64eb9d-3fdb-4edc-c6ab-3615ee13a421"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>I1</th>\n",
              "      <th>I2</th>\n",
              "      <th>I3</th>\n",
              "      <th>I4</th>\n",
              "      <th>I5</th>\n",
              "      <th>I6</th>\n",
              "      <th>I7</th>\n",
              "      <th>I8</th>\n",
              "      <th>I9</th>\n",
              "      <th>I10</th>\n",
              "      <th>I11</th>\n",
              "      <th>I12</th>\n",
              "      <th>I13</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>C15</th>\n",
              "      <th>C16</th>\n",
              "      <th>C17</th>\n",
              "      <th>C18</th>\n",
              "      <th>C19</th>\n",
              "      <th>C20</th>\n",
              "      <th>C21</th>\n",
              "      <th>C22</th>\n",
              "      <th>C23</th>\n",
              "      <th>C24</th>\n",
              "      <th>C25</th>\n",
              "      <th>C26</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17668.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>05db9164</td>\n",
              "      <td>08d6d899</td>\n",
              "      <td>9143c832</td>\n",
              "      <td>f56b7dd5</td>\n",
              "      <td>25c83c98</td>\n",
              "      <td>7e0ccccf</td>\n",
              "      <td>df5c2d18</td>\n",
              "      <td>0b153874</td>\n",
              "      <td>a73ee510</td>\n",
              "      <td>8f48ce11</td>\n",
              "      <td>a7b606c4</td>\n",
              "      <td>ae1bb660</td>\n",
              "      <td>eae197fd</td>\n",
              "      <td>b28479f6</td>\n",
              "      <td>bfef54b3</td>\n",
              "      <td>bad5ee18</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>87c6f83c</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0429f84b</td>\n",
              "      <td>-1</td>\n",
              "      <td>3a171ecb</td>\n",
              "      <td>c0d61a5c</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30251.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>68fd1e64</td>\n",
              "      <td>04e09220</td>\n",
              "      <td>95e13fd4</td>\n",
              "      <td>a1e6a194</td>\n",
              "      <td>25c83c98</td>\n",
              "      <td>fe6b92e5</td>\n",
              "      <td>f819e175</td>\n",
              "      <td>062b5529</td>\n",
              "      <td>a73ee510</td>\n",
              "      <td>ab9456b4</td>\n",
              "      <td>6153cf57</td>\n",
              "      <td>8882c6cd</td>\n",
              "      <td>769a1844</td>\n",
              "      <td>b28479f6</td>\n",
              "      <td>69f825dd</td>\n",
              "      <td>23056e4f</td>\n",
              "      <td>d4bb7bd8</td>\n",
              "      <td>6fc84bfb</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5155d8a3</td>\n",
              "      <td>-1</td>\n",
              "      <td>be7c41b4</td>\n",
              "      <td>ded4aac9</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>05db9164</td>\n",
              "      <td>38a947a1</td>\n",
              "      <td>3f55fb72</td>\n",
              "      <td>5de245c7</td>\n",
              "      <td>30903e74</td>\n",
              "      <td>7e0ccccf</td>\n",
              "      <td>b72ec13d</td>\n",
              "      <td>1f89b562</td>\n",
              "      <td>a73ee510</td>\n",
              "      <td>acce978c</td>\n",
              "      <td>3547565f</td>\n",
              "      <td>a5b0521a</td>\n",
              "      <td>12880350</td>\n",
              "      <td>b28479f6</td>\n",
              "      <td>c12fc269</td>\n",
              "      <td>95a8919c</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>675c9258</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2e01979f</td>\n",
              "      <td>-1</td>\n",
              "      <td>bcdee96c</td>\n",
              "      <td>6d5d1302</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16836.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>05db9164</td>\n",
              "      <td>8084ee93</td>\n",
              "      <td>02cf9876</td>\n",
              "      <td>c18be181</td>\n",
              "      <td>25c83c98</td>\n",
              "      <td>-1</td>\n",
              "      <td>e14874c9</td>\n",
              "      <td>0b153874</td>\n",
              "      <td>7cc72ec2</td>\n",
              "      <td>2462946f</td>\n",
              "      <td>636405ac</td>\n",
              "      <td>8fe001f4</td>\n",
              "      <td>31b42deb</td>\n",
              "      <td>07d13a8f</td>\n",
              "      <td>422c8577</td>\n",
              "      <td>36103458</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>52e44668</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>e587c466</td>\n",
              "      <td>-1</td>\n",
              "      <td>32c7478e</td>\n",
              "      <td>3b183c5c</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1990.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>05db9164</td>\n",
              "      <td>207b2d81</td>\n",
              "      <td>5d076085</td>\n",
              "      <td>862b5ba0</td>\n",
              "      <td>25c83c98</td>\n",
              "      <td>fbad5c96</td>\n",
              "      <td>17c22666</td>\n",
              "      <td>0b153874</td>\n",
              "      <td>a73ee510</td>\n",
              "      <td>534fc986</td>\n",
              "      <td>feb49a68</td>\n",
              "      <td>f24b551c</td>\n",
              "      <td>8978af5c</td>\n",
              "      <td>64c94865</td>\n",
              "      <td>32ec6582</td>\n",
              "      <td>b6d021e8</td>\n",
              "      <td>e5ba7672</td>\n",
              "      <td>25c88e42</td>\n",
              "      <td>21ddcdc9</td>\n",
              "      <td>b1252a9d</td>\n",
              "      <td>0e8585d2</td>\n",
              "      <td>-1</td>\n",
              "      <td>32c7478e</td>\n",
              "      <td>0d4a6d1a</td>\n",
              "      <td>001f3601</td>\n",
              "      <td>92c878de</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label   I1  I2     I3    I4  ...  C22       C23       C24       C25       C26\n",
              "0      0  0.0   3  260.0   0.0  ...   -1  3a171ecb  c0d61a5c        -1        -1\n",
              "1      0  0.0  -1   19.0  35.0  ...   -1  be7c41b4  ded4aac9        -1        -1\n",
              "2      0  0.0   0    2.0  12.0  ...   -1  bcdee96c  6d5d1302        -1        -1\n",
              "3      0  0.0  13    1.0   4.0  ...   -1  32c7478e  3b183c5c        -1        -1\n",
              "4      0  0.0   0  104.0  27.0  ...   -1  32c7478e  0d4a6d1a  001f3601  92c878de\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "SWxPFx7IpOQQ",
        "outputId": "39f55eb8-395a-4183-93dc-008d4de398cb"
      },
      "source": [
        "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
        "# label eencoding + minmax\n",
        "\n",
        "# Label Encoding: map the features to integer value from 0 ~ len(#unique) - 1\n",
        "for feat in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feat] = lbe.fit_transform(data[feat])\n",
        "mms = MinMaxScaler(feature_range=(0, 1))\n",
        "data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>I1</th>\n",
              "      <th>I2</th>\n",
              "      <th>I3</th>\n",
              "      <th>I4</th>\n",
              "      <th>I5</th>\n",
              "      <th>I6</th>\n",
              "      <th>I7</th>\n",
              "      <th>I8</th>\n",
              "      <th>I9</th>\n",
              "      <th>I10</th>\n",
              "      <th>I11</th>\n",
              "      <th>I12</th>\n",
              "      <th>I13</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>C15</th>\n",
              "      <th>C16</th>\n",
              "      <th>C17</th>\n",
              "      <th>C18</th>\n",
              "      <th>C19</th>\n",
              "      <th>C20</th>\n",
              "      <th>C21</th>\n",
              "      <th>C22</th>\n",
              "      <th>C23</th>\n",
              "      <th>C24</th>\n",
              "      <th>C25</th>\n",
              "      <th>C26</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001332</td>\n",
              "      <td>0.092362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034825</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.673469</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>96</td>\n",
              "      <td>146</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>117</td>\n",
              "      <td>127</td>\n",
              "      <td>157</td>\n",
              "      <td>7</td>\n",
              "      <td>127</td>\n",
              "      <td>126</td>\n",
              "      <td>8</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006750</td>\n",
              "      <td>0.402299</td>\n",
              "      <td>0.059628</td>\n",
              "      <td>0.117284</td>\n",
              "      <td>0.003322</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.154739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343137</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>179</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>58</td>\n",
              "      <td>97</td>\n",
              "      <td>79</td>\n",
              "      <td>7</td>\n",
              "      <td>72</td>\n",
              "      <td>26</td>\n",
              "      <td>7</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.077873</td>\n",
              "      <td>0.019934</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.505803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.09375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>52</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>31</td>\n",
              "      <td>122</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>129</td>\n",
              "      <td>97</td>\n",
              "      <td>8</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.000355</td>\n",
              "      <td>0.045977</td>\n",
              "      <td>0.033185</td>\n",
              "      <td>0.094967</td>\n",
              "      <td>0.016611</td>\n",
              "      <td>0.081633</td>\n",
              "      <td>0.028046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>117</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>164</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>61</td>\n",
              "      <td>104</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000333</td>\n",
              "      <td>0.036945</td>\n",
              "      <td>0.310345</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.067426</td>\n",
              "      <td>0.013289</td>\n",
              "      <td>0.653061</td>\n",
              "      <td>0.035783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>59</td>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>171</td>\n",
              "      <td>162</td>\n",
              "      <td>96</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>121</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label   I1        I2        I3        I4  ...  C22  C23  C24  C25  C26\n",
              "0      0  0.0  0.001332  0.092362  0.000000  ...    0    1   96    0    0\n",
              "1      0  0.0  0.000000  0.006750  0.402299  ...    0    7  112    0    0\n",
              "2      0  0.0  0.000333  0.000710  0.137931  ...    0    6   53    0    0\n",
              "3      0  0.0  0.004664  0.000355  0.045977  ...    0    0   32    0    0\n",
              "4      0  0.0  0.000333  0.036945  0.310345  ...    0    0    5    1   47\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdQFhZfoqBJ4"
      },
      "source": [
        "# 2.count #unique features for each sparse field,and record dense feature field name\n",
        "# for varlen(multi-valued) sparse features,you can use VarlenSparseFeat. Visit examples of using VarlenSparseFeat\n",
        "\n",
        "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4 )\n",
        "                        for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
        "                      for feat in dense_features]\n",
        "\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTwN6q_AtM_8"
      },
      "source": [
        "#fixlen_feature_columns"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbDpk8i744JB",
        "outputId": "bef4639b-16c6-496c-daf3-b58168587d21"
      },
      "source": [
        "# 3.generate input data for model\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=2018)\n",
        "train_model_input = {name:train[name] for name in feature_names}\n",
        "test_model_input = {name:test[name] for name in feature_names}\n",
        "\n",
        "train_model_input['C1']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155    16\n",
              "113     0\n",
              "36     11\n",
              "51     14\n",
              "81     16\n",
              "       ..\n",
              "148    19\n",
              "156     1\n",
              "149    11\n",
              "9       0\n",
              "102    10\n",
              "Name: C1, Length: 160, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g027c0KnG6HQ"
      },
      "source": [
        "#train_model_input"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTyf7wE944D3"
      },
      "source": [
        "# 4.Define Model,train,predict and evaluate\n",
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
        "model.compile(\"adam\", \"binary_crossentropy\",\n",
        "              metrics=['binary_crossentropy'], )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTD8uPBb44A9",
        "outputId": "3e05bf47-8ef6-451d-c684-aca02ae24878"
      },
      "source": [
        "history = model.fit(train_model_input, train[target].values,\n",
        "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
        "\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "\n",
        "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
        "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 7s - loss: 0.7907 - binary_crossentropy: 0.7907 - val_loss: 0.7620 - val_binary_crossentropy: 0.7620\n",
            "Epoch 2/10\n",
            "1/1 - 0s - loss: 0.7648 - binary_crossentropy: 0.7648 - val_loss: 0.7469 - val_binary_crossentropy: 0.7469\n",
            "Epoch 3/10\n",
            "1/1 - 0s - loss: 0.7398 - binary_crossentropy: 0.7398 - val_loss: 0.7323 - val_binary_crossentropy: 0.7323\n",
            "Epoch 4/10\n",
            "1/1 - 0s - loss: 0.7158 - binary_crossentropy: 0.7158 - val_loss: 0.7182 - val_binary_crossentropy: 0.7182\n",
            "Epoch 5/10\n",
            "1/1 - 0s - loss: 0.6925 - binary_crossentropy: 0.6925 - val_loss: 0.7044 - val_binary_crossentropy: 0.7044\n",
            "Epoch 6/10\n",
            "1/1 - 0s - loss: 0.6700 - binary_crossentropy: 0.6700 - val_loss: 0.6909 - val_binary_crossentropy: 0.6909\n",
            "Epoch 7/10\n",
            "1/1 - 0s - loss: 0.6479 - binary_crossentropy: 0.6479 - val_loss: 0.6775 - val_binary_crossentropy: 0.6775\n",
            "Epoch 8/10\n",
            "1/1 - 0s - loss: 0.6262 - binary_crossentropy: 0.6261 - val_loss: 0.6644 - val_binary_crossentropy: 0.6644\n",
            "Epoch 9/10\n",
            "1/1 - 0s - loss: 0.6046 - binary_crossentropy: 0.6045 - val_loss: 0.6514 - val_binary_crossentropy: 0.6514\n",
            "Epoch 10/10\n",
            "1/1 - 0s - loss: 0.5832 - binary_crossentropy: 0.5831 - val_loss: 0.6386 - val_binary_crossentropy: 0.6386\n",
            "test LogLoss 0.7\n",
            "test AUC 0.3385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8q55Ljk439g"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoW_59KLIthN"
      },
      "source": [
        "# Classification: Criteo with feature hashing on the fly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0ssJhox2djM",
        "outputId": "64b5f729-91d1-4267-dcc4-777a32d66fd2"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.feature_column import SparseFeat, DenseFeat,get_feature_names\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #data = pd.read_csv('./criteo_sample.txt')\n",
        "    data = pd.read_csv('https://raw.githubusercontent.com/shenweichen/DeepCTR/master/examples/criteo_sample.txt')\n",
        "    \n",
        "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
        "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
        "\n",
        "    data[sparse_features] = data[sparse_features].fillna('-1', )\n",
        "    data[dense_features] = data[dense_features].fillna(0, )\n",
        "    target = ['label']\n",
        "\n",
        "    # 1.do simple Transformation for dense features\n",
        "    mms = MinMaxScaler(feature_range=(0, 1))\n",
        "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "    # 2.set hashing space for each sparse field,and record dense feature field name\n",
        "\n",
        "    fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=1000,embedding_dim=4, use_hash=True, dtype='string')  # since the input is string\n",
        "                              for feat in sparse_features] + [DenseFeat(feat, 1, )\n",
        "                          for feat in dense_features]\n",
        "\n",
        "    linear_feature_columns = fixlen_feature_columns\n",
        "    dnn_feature_columns = fixlen_feature_columns\n",
        "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns, )\n",
        "\n",
        "    # 3.generate input data for model\n",
        "\n",
        "    train, test = train_test_split(data, test_size=0.2, random_state=2020)\n",
        "\n",
        "    train_model_input = {name:train[name] for name in feature_names}\n",
        "    test_model_input = {name:test[name] for name in feature_names}\n",
        "\n",
        "\n",
        "    # 4.Define Model,train,predict and evaluate\n",
        "    model = DeepFM(linear_feature_columns,dnn_feature_columns, task='binary')\n",
        "    model.compile(\"adam\", \"binary_crossentropy\",\n",
        "                  metrics=['binary_crossentropy'], )\n",
        "\n",
        "    history = model.fit(train_model_input, train[target].values,\n",
        "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
        "    pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "    print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
        "    print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 7s - loss: 0.7852 - binary_crossentropy: 0.7852 - val_loss: 0.7727 - val_binary_crossentropy: 0.7727\n",
            "Epoch 2/10\n",
            "1/1 - 0s - loss: 0.7621 - binary_crossentropy: 0.7621 - val_loss: 0.7580 - val_binary_crossentropy: 0.7579\n",
            "Epoch 3/10\n",
            "1/1 - 0s - loss: 0.7404 - binary_crossentropy: 0.7403 - val_loss: 0.7441 - val_binary_crossentropy: 0.7440\n",
            "Epoch 4/10\n",
            "1/1 - 0s - loss: 0.7197 - binary_crossentropy: 0.7197 - val_loss: 0.7309 - val_binary_crossentropy: 0.7309\n",
            "Epoch 5/10\n",
            "1/1 - 0s - loss: 0.6999 - binary_crossentropy: 0.6999 - val_loss: 0.7184 - val_binary_crossentropy: 0.7184\n",
            "Epoch 6/10\n",
            "1/1 - 0s - loss: 0.6807 - binary_crossentropy: 0.6807 - val_loss: 0.7064 - val_binary_crossentropy: 0.7064\n",
            "Epoch 7/10\n",
            "1/1 - 0s - loss: 0.6621 - binary_crossentropy: 0.6621 - val_loss: 0.6947 - val_binary_crossentropy: 0.6947\n",
            "Epoch 8/10\n",
            "1/1 - 0s - loss: 0.6438 - binary_crossentropy: 0.6438 - val_loss: 0.6834 - val_binary_crossentropy: 0.6834\n",
            "Epoch 9/10\n",
            "1/1 - 0s - loss: 0.6258 - binary_crossentropy: 0.6258 - val_loss: 0.6726 - val_binary_crossentropy: 0.6726\n",
            "Epoch 10/10\n",
            "1/1 - 0s - loss: 0.6080 - binary_crossentropy: 0.6080 - val_loss: 0.6621 - val_binary_crossentropy: 0.6621\n",
            "test LogLoss 0.6395\n",
            "test AUC 0.6201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv8464COIxGa"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4JJfSZjJV-u"
      },
      "source": [
        "# Regression: Movielens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N-l2oJ2IxDz",
        "outputId": "3194a45a-505f-453e-941e-f1ef80120e18"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.feature_column import SparseFeat,get_feature_names\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    data = pd.read_csv(\"DeepCTR/examples/movielens_sample.txt\")\n",
        "    sparse_features = [\"movie_id\", \"user_id\",\n",
        "                       \"gender\", \"age\", \"occupation\", \"zip\"]\n",
        "    target = ['rating']\n",
        "\n",
        "    # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
        "    for feat in sparse_features:\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "    # 2.count #unique features for each sparse field\n",
        "    fixlen_feature_columns = [SparseFeat(feat, data[feat].max() + 1,embedding_dim=4)\n",
        "                              for feat in sparse_features]\n",
        "    linear_feature_columns = fixlen_feature_columns\n",
        "    dnn_feature_columns = fixlen_feature_columns\n",
        "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    # 3.generate input data for model\n",
        "    train, test = train_test_split(data, test_size=0.2, random_state=2020)\n",
        "    train_model_input = {name:train[name].values for name in feature_names}\n",
        "    test_model_input = {name:test[name].values for name in feature_names}\n",
        "\n",
        "    # 4.Define Model,train,predict and evaluate\n",
        "    model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "    model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "\n",
        "    history = model.fit(train_model_input, train[target].values,\n",
        "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
        "    pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "    print(\"test MSE\", round(mean_squared_error(\n",
        "        test[target].values, pred_ans), 4))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 2s - loss: 13.4138 - mse: 13.4138 - val_loss: 15.6879 - val_mse: 15.6879\n",
            "Epoch 2/10\n",
            "1/1 - 0s - loss: 13.2782 - mse: 13.2782 - val_loss: 15.5574 - val_mse: 15.5574\n",
            "Epoch 3/10\n",
            "1/1 - 0s - loss: 13.1353 - mse: 13.1353 - val_loss: 15.4163 - val_mse: 15.4163\n",
            "Epoch 4/10\n",
            "1/1 - 0s - loss: 12.9816 - mse: 12.9816 - val_loss: 15.2659 - val_mse: 15.2659\n",
            "Epoch 5/10\n",
            "1/1 - 0s - loss: 12.8179 - mse: 12.8179 - val_loss: 15.1055 - val_mse: 15.1055\n",
            "Epoch 6/10\n",
            "1/1 - 0s - loss: 12.6436 - mse: 12.6436 - val_loss: 14.9349 - val_mse: 14.9349\n",
            "Epoch 7/10\n",
            "1/1 - 0s - loss: 12.4583 - mse: 12.4583 - val_loss: 14.7533 - val_mse: 14.7533\n",
            "Epoch 8/10\n",
            "1/1 - 0s - loss: 12.2610 - mse: 12.2610 - val_loss: 14.5601 - val_mse: 14.5601\n",
            "Epoch 9/10\n",
            "1/1 - 0s - loss: 12.0510 - mse: 12.0510 - val_loss: 14.3545 - val_mse: 14.3545\n",
            "Epoch 10/10\n",
            "1/1 - 0s - loss: 11.8273 - mse: 11.8273 - val_loss: 14.1355 - val_mse: 14.1355\n",
            "test MSE 13.4891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-1G_iSQJag9"
      },
      "source": [
        "# Multi-value Input : Movielens \n",
        "\n",
        "也就是如果categorical feature有多个values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RDZYB6cIxA9",
        "outputId": "e8294486-28e3-4839-9cc1-c14ebc8aa507"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.feature_column import SparseFeat, VarLenSparseFeat,get_feature_names\n",
        "\n",
        "\n",
        "def split(x):\n",
        "    key_ans = x.split('|')\n",
        "    for key in key_ans:\n",
        "        if key not in key2index:\n",
        "            # Notice : input value 0 is a special \"padding\",so we do not use 0 to encode valid feature for sequence input\n",
        "            key2index[key] = len(key2index) + 1\n",
        "    return list(map(lambda x: key2index[x], key_ans))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = pd.read_csv(\"DeepCTR/examples/movielens_sample.txt\")\n",
        "    sparse_features = [\"movie_id\", \"user_id\",\n",
        "                       \"gender\", \"age\", \"occupation\", \"zip\", ]\n",
        "    target = ['rating']\n",
        "\n",
        "    # 1.Label Encoding for sparse features,and process sequence features\n",
        "    for feat in sparse_features:\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "    # preprocess the sequence feature\n",
        "\n",
        "    key2index = {}\n",
        "    genres_list = list(map(split, data['genres'].values))\n",
        "    genres_length = np.array(list(map(len, genres_list)))\n",
        "    max_len = max(genres_length)\n",
        "    # Notice : padding=`post`\n",
        "    genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )\n",
        "\n",
        "    # 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
        "\n",
        "    fixlen_feature_columns = [SparseFeat(feat, data[feat].max() + 1,embedding_dim=4)\n",
        "                        for feat in sparse_features]\n",
        "\n",
        "    use_weighted_sequence = False\n",
        "    if use_weighted_sequence:\n",
        "        varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres',vocabulary_size=len(\n",
        "            key2index) + 1,embedding_dim=4), maxlen= max_len, combiner='mean',weight_name='genres_weight')]  # Notice : value 0 is for padding for sequence input feature\n",
        "    else:\n",
        "        varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres',vocabulary_size= len(\n",
        "            key2index) + 1,embedding_dim=4), maxlen=max_len, combiner='mean',weight_name=None)]  # Notice : value 0 is for padding for sequence input feature\n",
        "\n",
        "    linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "    dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "\n",
        "    feature_names = get_feature_names(linear_feature_columns+dnn_feature_columns)\n",
        "\n",
        "\n",
        "    # 3.generate input data for model\n",
        "    model_input = {name:data[name] for name in feature_names}#\n",
        "    model_input[\"genres\"] = genres_list\n",
        "    model_input[\"genres_weight\"] =  np.random.randn(data.shape[0],max_len,1)\n",
        "\n",
        "\n",
        "    # 4.Define Model,compile and train\n",
        "    model = DeepFM(linear_feature_columns,dnn_feature_columns,task='regression')\n",
        "\n",
        "    model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "    history = model.fit(model_input, data[target].values,\n",
        "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:591: UserWarning: Input dict contained keys ['genres_weight'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 - 3s - loss: 14.2996 - mse: 14.2996 - val_loss: 13.3741 - val_mse: 13.3741\n",
            "Epoch 2/10\n",
            "1/1 - 0s - loss: 14.1497 - mse: 14.1497 - val_loss: 13.2381 - val_mse: 13.2381\n",
            "Epoch 3/10\n",
            "1/1 - 0s - loss: 13.9874 - mse: 13.9874 - val_loss: 13.0924 - val_mse: 13.0924\n",
            "Epoch 4/10\n",
            "1/1 - 0s - loss: 13.8131 - mse: 13.8131 - val_loss: 12.9355 - val_mse: 12.9355\n",
            "Epoch 5/10\n",
            "1/1 - 0s - loss: 13.6255 - mse: 13.6255 - val_loss: 12.7666 - val_mse: 12.7666\n",
            "Epoch 6/10\n",
            "1/1 - 0s - loss: 13.4240 - mse: 13.4240 - val_loss: 12.5852 - val_mse: 12.5852\n",
            "Epoch 7/10\n",
            "1/1 - 0s - loss: 13.2078 - mse: 13.2078 - val_loss: 12.3907 - val_mse: 12.3907\n",
            "Epoch 8/10\n",
            "1/1 - 0s - loss: 12.9755 - mse: 12.9755 - val_loss: 12.1822 - val_mse: 12.1822\n",
            "Epoch 9/10\n",
            "1/1 - 0s - loss: 12.7261 - mse: 12.7261 - val_loss: 11.9591 - val_mse: 11.9591\n",
            "Epoch 10/10\n",
            "1/1 - 0s - loss: 12.4582 - mse: 12.4582 - val_loss: 11.7204 - val_mse: 11.7204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFc6mOSFJpH7"
      },
      "source": [
        "# Multi-value Input : Movielens with feature hashing on the fly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P14A3VcPIw-N",
        "outputId": "7e6324d1-a447-47b4-b527-3dfa660efdc6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from deepctr.feature_column import SparseFeat, VarLenSparseFeat,get_feature_names\n",
        "from deepctr.models import DeepFM\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = pd.read_csv(\"DeepCTR/examples/movielens_sample.txt\")\n",
        "    sparse_features = [\"movie_id\", \"user_id\",\n",
        "                       \"gender\", \"age\", \"occupation\", \"zip\", ]\n",
        "\n",
        "    data[sparse_features] = data[sparse_features].astype(str)\n",
        "    target = ['rating']\n",
        "\n",
        "    # 1.Use hashing encoding on the fly for sparse features,and process sequence features\n",
        "\n",
        "    genres_list = list(map(lambda x: x.split('|'), data['genres'].values))\n",
        "    genres_length = np.array(list(map(len, genres_list)))\n",
        "    max_len = max(genres_length)\n",
        "\n",
        "    # Notice : padding=`post`\n",
        "    genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', dtype=str, value=0)\n",
        "\n",
        "    # 2.set hashing space for each sparse field and generate feature config for sequence feature\n",
        "\n",
        "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique() * 5, embedding_dim=4, use_hash=True, dtype='string')\n",
        "                              for feat in sparse_features]\n",
        "    varlen_feature_columns = [\n",
        "        VarLenSparseFeat(SparseFeat('genres', vocabulary_size=100, embedding_dim=4, use_hash=True, dtype=\"string\"),\n",
        "                         maxlen=max_len, combiner='mean',\n",
        "                         )]  # Notice : value 0 is for padding for sequence input feature\n",
        "    linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "    dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "    # 3.generate input data for model\n",
        "    model_input = {name: data[name] for name in feature_names}\n",
        "    model_input['genres'] = genres_list\n",
        "\n",
        "    # 4.Define Model,compile and train\n",
        "    model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "\n",
        "    model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "    history = model.fit(model_input, data[target].values,\n",
        "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 3s - loss: 14.2997 - mse: 14.2997 - val_loss: 13.3717 - val_mse: 13.3717\n",
            "Epoch 2/10\n",
            "1/1 - 0s - loss: 14.1511 - mse: 14.1511 - val_loss: 13.2344 - val_mse: 13.2344\n",
            "Epoch 3/10\n",
            "1/1 - 0s - loss: 13.9906 - mse: 13.9906 - val_loss: 13.0876 - val_mse: 13.0876\n",
            "Epoch 4/10\n",
            "1/1 - 0s - loss: 13.8194 - mse: 13.8194 - val_loss: 12.9316 - val_mse: 12.9316\n",
            "Epoch 5/10\n",
            "1/1 - 0s - loss: 13.6376 - mse: 13.6376 - val_loss: 12.7655 - val_mse: 12.7655\n",
            "Epoch 6/10\n",
            "1/1 - 0s - loss: 13.4446 - mse: 13.4446 - val_loss: 12.5887 - val_mse: 12.5887\n",
            "Epoch 7/10\n",
            "1/1 - 0s - loss: 13.2395 - mse: 13.2395 - val_loss: 12.4003 - val_mse: 12.4003\n",
            "Epoch 8/10\n",
            "1/1 - 0s - loss: 13.0211 - mse: 13.0211 - val_loss: 12.1996 - val_mse: 12.1996\n",
            "Epoch 9/10\n",
            "1/1 - 0s - loss: 12.7886 - mse: 12.7886 - val_loss: 11.9859 - val_mse: 11.9859\n",
            "Epoch 10/10\n",
            "1/1 - 0s - loss: 12.5411 - mse: 12.5411 - val_loss: 11.7586 - val_mse: 11.7586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrpDG-UYJ20C"
      },
      "source": [
        "# Estimator with `TFRecord`: Classification Criteo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Qeko4cIw7j",
        "outputId": "7f40eaa3-57f9-4429-a65e-e9c440d772c0"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.ops.parsing_ops import  FixedLenFeature\n",
        "from deepctr.estimator import DeepFMEstimator\n",
        "from deepctr.estimator.inputs import input_fn_tfrecord\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1.generate feature_column for linear part and dnn part\n",
        "\n",
        "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
        "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
        "\n",
        "    dnn_feature_columns = []\n",
        "    linear_feature_columns = []\n",
        "\n",
        "    for i, feat in enumerate(sparse_features):\n",
        "        dnn_feature_columns.append(tf.feature_column.embedding_column(\n",
        "            tf.feature_column.categorical_column_with_identity(feat, 1000), 4))\n",
        "        linear_feature_columns.append(tf.feature_column.categorical_column_with_identity(feat, 1000))\n",
        "    for feat in dense_features:\n",
        "        dnn_feature_columns.append(tf.feature_column.numeric_column(feat))\n",
        "        linear_feature_columns.append(tf.feature_column.numeric_column(feat))\n",
        "\n",
        "    # 2.generate input data for model\n",
        "\n",
        "    feature_description = {k: FixedLenFeature(dtype=tf.int64, shape=1) for k in sparse_features}\n",
        "    feature_description.update(\n",
        "        {k: FixedLenFeature(dtype=tf.float32, shape=1) for k in dense_features})\n",
        "    feature_description['label'] = FixedLenFeature(dtype=tf.float32, shape=1)\n",
        "\n",
        "    train_model_input = input_fn_tfrecord('DeepCTR/examples/criteo_sample.tr.tfrecords', feature_description, 'label', batch_size=256,\n",
        "                                          num_epochs=1, shuffle_factor=10)\n",
        "    test_model_input = input_fn_tfrecord('DeepCTR/examples/criteo_sample.te.tfrecords', feature_description, 'label',\n",
        "                                         batch_size=2 ** 14, num_epochs=1, shuffle_factor=0)\n",
        "\n",
        "    # 3.Define Model,train,predict and evaluate\n",
        "    model = DeepFMEstimator(linear_feature_columns, dnn_feature_columns, task='binary', \n",
        "                            config=tf.estimator.RunConfig(tf_random_seed=2021))\n",
        "\n",
        "    model.train(train_model_input)\n",
        "    eval_result = model.evaluate(test_model_input)\n",
        "\n",
        "    print(eval_result)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp5rfji1ro\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp5rfji1ro', '_tf_random_seed': 2021, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py:553: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py:2074: IdentityCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py:2192: IdentityCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py:557: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py:1974: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py:2192: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py:205: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/feature_column/feature_column.py:206: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deepctr/estimator/utils.py:210: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deepctr/estimator/utils.py:59: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/adagrad.py:77: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp5rfji1ro/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 349.83713, step = 0\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1...\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp5rfji1ro/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1...\n",
            "INFO:tensorflow:Loss for final step: 349.83713.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-07-12T16:37:36\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp5rfji1ro/model.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 2.26423s\n",
            "INFO:tensorflow:Finished evaluation at 2021-07-12-16:37:38\n",
            "INFO:tensorflow:Saving dict for global step 1: AUC = 0.49702382, LogLoss = 2.2537224, global_step = 1, label/mean = 0.3, loss = 90.15277, prediction/mean = 0.2906259\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1: /tmp/tmp5rfji1ro/model.ckpt-1\n",
            "{'AUC': 0.49702382, 'LogLoss': 2.2537224, 'label/mean': 0.3, 'loss': 90.15277, 'prediction/mean': 0.2906259, 'global_step': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HygffvY6KOB4"
      },
      "source": [
        "# Estimator with Pandas DataFrame: Classification Criteo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWzeeRMrIw4x",
        "outputId": "26c3b774-3802-481d-c2c0-ef0a34e38798"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "from deepctr.estimator import DeepFMEstimator\n",
        "from deepctr.estimator.inputs import input_fn_pandas\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = pd.read_csv('DeepCTR/examples/criteo_sample.txt')\n",
        "\n",
        "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
        "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
        "\n",
        "    data[sparse_features] = data[sparse_features].fillna('-1', )\n",
        "    data[dense_features] = data[dense_features].fillna(0, )\n",
        "    target = ['label']\n",
        "\n",
        "    # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
        "    for feat in sparse_features:\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "    mms = MinMaxScaler(feature_range=(0, 1))\n",
        "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "    # 2.count #unique features for each sparse field,and record dense feature field name\n",
        "\n",
        "    dnn_feature_columns = []\n",
        "    linear_feature_columns = []\n",
        "\n",
        "    for i, feat in enumerate(sparse_features):\n",
        "        dnn_feature_columns.append(tf.feature_column.embedding_column(\n",
        "            tf.feature_column.categorical_column_with_identity(feat, data[feat].max() + 1), 4))\n",
        "        linear_feature_columns.append(tf.feature_column.categorical_column_with_identity(feat, data[feat].max() + 1))\n",
        "    for feat in dense_features:\n",
        "        dnn_feature_columns.append(tf.feature_column.numeric_column(feat))\n",
        "        linear_feature_columns.append(tf.feature_column.numeric_column(feat))\n",
        "\n",
        "    # 3.generate input data for model\n",
        "\n",
        "    train, test = train_test_split(data, test_size=0.2, random_state=2021)\n",
        "\n",
        "    # Not setting default value for continuous feature. filled with mean.\n",
        "\n",
        "    train_model_input = input_fn_pandas(train, sparse_features + dense_features, 'label', shuffle=True)\n",
        "    test_model_input = input_fn_pandas(test, sparse_features + dense_features, None, shuffle=False)\n",
        "\n",
        "    # 4.Define Model,train,predict and evaluate\n",
        "    model = DeepFMEstimator(linear_feature_columns, dnn_feature_columns, task='binary', \n",
        "                            config=tf.estimator.RunConfig(tf_random_seed=2021))\n",
        "\n",
        "    model.train(train_model_input)\n",
        "    pred_ans_iter = model.predict(test_model_input)\n",
        "    pred_ans = list(map(lambda x: x['pred'], pred_ans_iter))\n",
        "    #\n",
        "    print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
        "    print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deepctr/estimator/inputs.py:11: The name tf.estimator.inputs.pandas_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.pandas_input_fn instead.\n",
            "\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp769zctih\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp769zctih', '_tf_random_seed': 2021, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:65: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py:907: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp769zctih/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 572.73376, step = 0\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1...\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp769zctih/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1...\n",
            "INFO:tensorflow:Loss for final step: 572.73376.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp769zctih/model.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "test LogLoss inf\n",
            "test AUC 0.4828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:2295: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj4TGb22Iw19"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e91hNFWk4FSh"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}